{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Leaper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.给定一个数，检查是否可由数组中的两个数相加而成(hash)\n",
    "解法一，穷举，从数组中任意选取两个数，判定它们的和是否为输入的那个数字，时间复杂度为$O(n^2)$\n",
    "```\n",
    "test_sets = [2, 4, 7, 1, 15, 11]\n",
    "def findSum(test_sets, value):\n",
    "    for i in range(len(test_sets)):\n",
    "        for j in range(i, len(test_sets)):\n",
    "            if test_sets[i] + test_sets[j] == value:\n",
    "                print (i,j+\\n+test_sets[i],test_sets[j])\n",
    "    return None\n",
    "findSum(test_sets, 26)\n",
    "findSum(test_sets, 39)\n",
    "```\n",
    "\n",
    "解法二，a[i]在序列中，如果a[i] + a[k] = sum，那么sum - a[i] 也必然在序列中，首先用给定数值减去数组，得到第二个数组。在第一个数组中以指针i从数组最左端开始向右扫描，第二个数组以指针j从数组最右端开始向左扫描，如果第一个数组出现了和第二个数组一样的数，即a[i] = a[j]，就找出这两个数了。 时间复杂度为$O(n)$.(也可以构建hashtable，查找时时间复杂度为O(1))\n",
    "```\n",
    "def findSum2(test_sets, value):\n",
    "    diff_sets = map(lambda x: value - x, test_sets)\n",
    "    start_ = []\n",
    "    end_ = []\n",
    "    for i in range(len(test_sets)):\n",
    "        start_value = test_sets[i]\n",
    "        end_value = diff_sets[-i-1]\n",
    "        if start_value == end_value:\n",
    "            return first_value, test_sets[-i-1]\n",
    "        elif start_value in end_:\n",
    "            return start_value, test_sets[-end_.index(start_value)-1]\n",
    "        elif end_value in start_:\n",
    "            return end_value, test_sets[start_.index(end_value)]\n",
    "        else:\n",
    "            start_.append(test_sets[i])\n",
    "            end_.append()\n",
    "    return None\n",
    "```\n",
    "\n",
    "解法三，如果数组是无序的，先进行排序$O(nlogn)$，然后用两个指针i,j,各自指向数组的首尾两端，令i=0，j=n-1,然后i++，j--，逐次判断a[i] + a[j] == sum\n",
    "\n",
    "- 如果某一刻a[i] + a[j] > sum, 则要想办法让sum的值减小，所以此刻i不懂，j--;\n",
    "- 如果某一个a[i] + a[j] < sum, 则要想办法让sum的值增大，所以此刻i++, j不动。\n",
    "\n",
    "时间复杂度为$O(nlogn + n)$\n",
    "\n",
    "```\n",
    "def findSum3(test_sets, value):\n",
    "    test_sets.sort()\n",
    "    done = False\n",
    "    i = 0\n",
    "    j = len(test_sets)-1\n",
    "    while i != j:\n",
    "        sums = test_sets[i] + test_sets[j]\n",
    "        if sums == value:\n",
    "            return test_sets[i], test_sets[j]\n",
    "        elif sums > value:\n",
    "            j -= 1\n",
    "        else:\n",
    "            i += 1\n",
    "    return None\n",
    "```\n",
    "\n",
    "#### 2.给定一道判断题，甲做对一个题的概率是95%,乙做对一道题的概率是90%，现有一道题两人都判断为正，问该题为正的概率是多少\n",
    "\n",
    "甲，乙选择'正确'的事件为A，B <br>\n",
    "题目答案为正的事件为C\n",
    "\n",
    "P(A|C) = P(A|$\\bar{C}$) = 0.95 <br>\n",
    "P(B|C) = P(B|$\\bar{C}$) = 0.8\n",
    "\n",
    "问题是求P(C|AB)\n",
    "P(C|AB) = $\\frac{P(AB|C)*P(C)}{P(AB|C)*P(C) + P(AB|\\bar{C})*P(\\bar{C})}$ <br>\n",
    "\n",
    "结果为$\\frac{0.9*0.95*0.5}{0.9*0.95*0.5+0.1*0.05*0.5}$ \n",
    "<br>\n",
    "\n",
    "#### 3.树模型对数据源的要求\n",
    "\n",
    "- 决策树对数据分布没有特别严格的要求。\n",
    "- 对缺失值很宽容，几乎不做任何处理就可以应用。\n",
    "- 不容易受异常值的影响。\n",
    "- 可以同时对付数据中线性和非线性的关系。\n",
    "\n",
    "#### 4.线性回归中的正则项，L1和L2的区别，为什么如此设计\n",
    "\n",
    "假设输出结果可以被输入线性拟合, $y_n = \\beta x_n + \\epsilon$,<br>\n",
    "$\\epsilon$来自均值为0，方差为$\\sigma^2$，可以得到$y$的高斯似然分布:$\\sum_{n=1}^{N}N(y_n|\\beta x_n, \\sigma^2)$.对参数$\\beta$加入先验概率$N(\\beta|0,\\lambda^-1)$(即假设$\\beta$取自高斯分布), $\\lambda$是严格的正交向量，结合似然和先验概率可以得到:\n",
    "$$\\sum_{n=1}^{N}N(y_n|\\beta x_n, \\sigma^2)N(\\beta|0,\\lambda^{-1})$$,去对数后并消掉一些常数后:\n",
    "$$\\sum_{n=1}^{N}-\\frac{1}{\\sigma^2}(y_n-\\beta x_n)^2 - \\lambda \\beta^2 + const.$$<br>\n",
    "$$posterior \\propto likelihood \\times prior $$<br>\n",
    "$$log(posterior) \\sim log(likelihood) + log(penalty)$$<br>\n",
    "计算$\\beta$使得表达式最大化得到MAP. 相应的，L1正则是对参数$\\beta$加入拉普勒斯先验概率$\\lambda \\beta$\n",
    "\n",
    "#### 5. 模型聚合的方法\n",
    "- Uniform blending\n",
    "- linear blending\n",
    "- bagging（对数据集有放回的取样）\n",
    "\n",
    "#### 6.不平衡数据集如何训练\n",
    "\n",
    "- Sampling(上采样生成新数据，下采样减少已有数据)\n",
    "    - 随机采样\n",
    "    - SMOTE算法(对少数类样本进行分析并根据少数类样本人工合成新样本添加到数据集中)\n",
    "    - Informed Undersampling(在多数类的数据中通过n次有放回抽样生成n份子集，少数类样本分别和这n份样本合并训练一个模型，这样可以得到n个模型，最终的模型是这n个模型预测结果的平均值。)\n",
    "- Cost sensitive methods(对不同的分类结果设计不同的损失函数)\n",
    "    - 代价矩阵\n",
    "    - 代价敏感学习，将代价用于权重的调整\n",
    "    - AdaCost(AdaCost算法修改了Adaboost算法的权重更新策略，其基本思想是对于代价高的误分类样本大大地提高其权重，而对于代价高的正确分类样本适当地降低其权重，使其权重降低相对较小)\n",
    "- Kernel-based methods(修改核函数来偏移hyperplace,抵消不平衡数据造成的hyperplace偏移)\n",
    "- One-class learning or novelty detection methods\n",
    "\n",
    "\n",
    "#### 7. 查准率，查全率， F1， ROC， AUC, G-MEAN\n",
    "- $P = \\frac{TP}{TP+FP}$, $R = \\frac{TP}{TP+FN}$,查准率和查全率有一定矛盾，查准率较高时，查全率往往偏低；而查全率高时，查准率往往偏低。<br>\n",
    "- $F1 = \\frac{2 \\times P \\times R}{P + R}$，F1与基于查准率和查全率的调和平均，可以不同偏好。\n",
    "\n",
    "<br>\n",
    "- ROC(Receiver Operating Characteristic)曲线由TPR和FPR组成<br>\n",
    "    - $TPR = \\frac{TP}{TP + FN}$，正例中分类为正例的概率<br>\n",
    "    - $FPR = \\frac{FP}{TN + FP}$,负例中分类为正例的概率<br>\n",
    "选择不同的threshold(阀值)，可以得到不同的TPR与FPR，曲线越向左上方倾斜，分类器的分类的效果越好<br>\n",
    "- AUC为ROC曲线下方的面积$AUC = \\frac{1}{2}\\sum_{i=1}^{m-1}(x_{i+1}- x_i)\\dot(y_i + y_{i+1})$<br>\n",
    " 针对不同的分类结果，可以对分类错误的样本分配不同的代价系数，从而解决样本不均衡的情况.<br>\n",
    "- G-mean:$\\sqrt{\\frac{TP}{TP + FN}\\times \\frac{TN}{TN +FP}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多牛媒体\n",
    "1. 对图像的预处理与增强\n",
    "2. cross-entropy， 以及SVM和Softmax的区别， Softmax与Logistic regression的区别\n",
    "3. 什么是堆树\n",
    "4. 矩阵的秩\n",
    "5. 特征值与特征向量\n",
    "6. 快速排序\n",
    "7. 如何处理深度神经网络的过拟合\n",
    "8. 熟悉哪些推荐算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "恒昌利通\n",
    "1. 如何构造语音识别的特征\n",
    "2. 如何增加数据源，进行降噪"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创新工场\n",
    "1. 二位数组，横纵递增，如何找到给定k值\n",
    "2. 牛顿法求2的开放\n",
    "3. 了解哪些推荐算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boss直聘\n",
    "1. SVM推倒\n",
    "2. 设计埋点，有哪些用户信息可以用来构造特征\n",
    "3. 一个用户的期望薪资是10000-20000，有两个商家，Boss-a的薪资范围是10000-15000， Boss-b的薪资范围是18000-22000，把用户推荐给哪个Boss\n",
    "4. 如何召回流失用户，有哪些措施"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "混沌研习社\n",
    "1. SVM推导\n",
    "2. 冒泡排序\n",
    "3. ID3与C4.5的区别\n",
    "4. 单链表倒置"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
